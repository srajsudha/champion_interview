{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b337f47e-5ae6-468e-a3bc-da43bd79e279",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Churn Prediction Realtime Inference\n",
    "\n",
    "We have just seen how to get predictions in batches. Now, we will deploy the features and model to make realtime predictions via REST API call. Customer application teams can embed this predictive capability into customer-facing applications and apply a retention strategy for customers predicted to churn as they interact with the application.\n",
    "\n",
    "Because the predictions are to be made in a customer-facing application as the customer interacts with it, they have to be returned with low-latency.\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/mlops/advanced/banners/mlflow-uc-end-to-end-advanced-5.png?raw=true\" width=\"1200\">\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-science&org_id=3227024006299960&notebook=%2F02-mlops-advanced%2F06_serve_features_and_model&demo_name=mlops-end2end&event=VIEW&path=%2F_dbdemos%2Fdata-science%2Fmlops-end2end%2F02-mlops-advanced%2F06_serve_features_and_model&version=1\">\n",
    "<!-- [metadata={\"description\":\"MLOps end2end workflow: Load the model from MLFLow and run inferences, in batch or realtime.\",\n",
    " \"authors\":[\"quentin.ambard@databricks.com\"],\n",
    " \"db_resources\":{},\n",
    "  \"search_tags\":{\"vertical\": \"retail\", \"step\": \"Model testing\", \"components\": [\"mlflow\"]},\n",
    "                 \"canonicalUrl\": {\"AWS\": \"\", \"Azure\": \"\", \"GCP\": \"\"}}] -->\n",
    "\n",
    "<br>\n",
    "\n",
    "To serve the features and model, we will:\n",
    "\n",
    "- Make the features available for low-latency retrieval by the model through Databrick's online tables\n",
    "- Deploy the registered model from Unity Catalog to a Model Serving endpoint for low latency serving\n",
    "\n",
    "These tasks can be done in the UI. They can also be automated by leveraging the Databricks Python SDK ([AWS](https://docs.databricks.com/en/dev-tools/sdk-python.html#)|[Azure](https://learn.microsoft.com/en-us/azure/databricks/dev-tools/sdk-python)|[GCP](https://docs.gcp.databricks.com/dev-tools/sdk-python.html)) available in Databricks Runtime 13.3LTS+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f5cf26c-5b55-4d0e-a1ec-3e454950ffe8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Databricks Python SDK [for MLR < 13.3] and MLflow version for model lineage in UC [for MLR < 15.2]"
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet mlflow==2.19\n",
    "%pip install -U databricks-sdk\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83afaa48-57ee-478a-be67-ceefb5a33963",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ../_resources/00-setup $reset_all_data=false $adv_mlops=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f881701-d8fc-4e21-9530-82f9c7b358bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Serve features with Databricks online tables\n",
    "\n",
    "For serving predictions queries with low-latency, publish the features to Databricks online tables and serve them in real time to the model.\n",
    "\n",
    "During the feature engineering step, we have created a Delta Table as an offline feature table. Recall that any Delta Table that has a primary key can be a feature table in Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a34b784e-e571-4af0-851c-6bc3b716a0fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Enable Change-Data-Feed on Feature Table for performance considerations\n",
    "\n",
    "An online table is a read-only copy of a Delta Table that is stored in row-oriented format optimized for online access. \n",
    "\n",
    "Databricks allows the online tables to be refreshed efficiently whenever there are updates to the underlying feature tables. This is enabled through the Change Data Feed feature of Delta Lake. Let us first enable Change Data Feed on the underlying feature table `churn_feature_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6cdc2cf-ea3e-4e2f-938c-76f574ec4755",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "ALTER TABLE advanced_churn_feature_table SET TBLPROPERTIES (delta.enableChangeDataFeed = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a58afdb-9479-4b34-a11b-a0381d6b1a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Create the Online Table\n",
    "\n",
    "You can create an online table from the Catalog Explorer UI, or by using the API. The steps are described below. For more details, see the Databricks documentation ([AWS](https://docs.databricks.com/en/machine-learning/feature-store/online-tables.html#create)|[Azure](https://learn.microsoft.com/azure/databricks/machine-learning/feature-store/online-tables#create)). For information about required permissions, see Permissions ([AWS](https://docs.databricks.com/en/machine-learning/feature-store/online-tables.html#user-permissions)|[Azure](https://learn.microsoft.com/azure/databricks/machine-learning/feature-store/online-tables#user-permissions)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19b70e27-a7f5-4ba4-9910-71f91f9df0e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### OPTION 1: Use the Catalog Explorer UI\n",
    "In Catalog Explorer, navigate to the source table that you want to sync to an online table. From the **Create** menu, select **Online table**.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/mlops/advanced/06_create_online_table.gif?raw=true\" width=\"1200\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Fill in the following fields:\n",
    "\n",
    "* **Name**: `churn_feature_table_online_table`\n",
    "  * This is the name to use for the online table in Unity Catalog.\n",
    "* **Primary Key**: `customer_id`\n",
    "  * This is the column in the source table to use as primary key in the online table.\n",
    "* **Timeseries Key**: `transaction_ts`\n",
    "  * This is the column in the source table to use as the timeseries key.\n",
    "\n",
    "Leave the **Sync mode** as **Snapshot**. This is the synchronization strategy to update the pipeline from its source feature table. Refer to the documentation to learn more ([AWS](https://docs.databricks.com/en/machine-learning/feature-store/online-tables.html)|[Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/feature-store/online-tables)).\n",
    "\n",
    "When you are done, click Confirm.\n",
    "\n",
    "You are brought to the online table page. Wait for the synchronization to complete.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/mlops/advanced/06_online_table.png?raw=true\" width=\"1200\">\n",
    "\n",
    "<br>\n",
    "\n",
    "*The new online table is created under the catalog, schema, and name specified in the creation dialog. In Catalog Explorer, the online table is indicated by online table icon.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e780ff3d-dc69-4029-89e4-11d0b43db2ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### OPTION 2: Use the Databricks SDK \n",
    "\n",
    "The other alternative is the Databricks' python-sdk [AWS](https://docs.databricks.com/en/machine-learning/feature-store/online-tables.html#api-sdk) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/feature-store/online-tables). Let's  first define the table specifications, then create the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0af55dc4-a2ed-4eb7-b10a-3a2841fe5595",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "# Create workspace client for the Databricks Python SDK\n",
    "w = WorkspaceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a434e331-e22d-4dcd-8215-9967044f44c4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Drop any existing online table (optional)"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "try:\n",
    "  online_table_specs = w.online_tables.get(f\"{catalog}.{db}.advanced_churn_feature_table_online_table\")\n",
    "  \n",
    "  # Drop existing online feature table\n",
    "  w.online_tables.delete(f\"{catalog}.{db}.advanced_churn_feature_table_online_table\")\n",
    "  print(f\"Dropping online feature table: {catalog}.{db}.advanced_churn_feature_table_online_table\")\n",
    "\n",
    "  # Wait for deletion to complete\n",
    "  while online_table_specs is not None:\n",
    "    online_table_specs = w.online_tables.get(f\"{catalog}.{db}.advanced_churn_feature_table_online_table\")\n",
    "\n",
    "except Exception as e:\n",
    "  pprint(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffecf279-0cce-43dd-a34d-1618541d4f12",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create the online table specification"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk.service.catalog import (\n",
    "    OnlineTable,\n",
    "    OnlineTableSpec,\n",
    "    OnlineTableSpecTriggeredSchedulingPolicy,\n",
    ")\n",
    "\n",
    "# Create an online table specification\n",
    "churn_features_online_store_spec = OnlineTableSpec(\n",
    "    primary_key_columns=[\"customer_id\"],\n",
    "    timeseries_key=\"transaction_ts\",\n",
    "    source_table_full_name=f\"{catalog}.{db}.advanced_churn_feature_table\",\n",
    "    run_triggered=OnlineTableSpecTriggeredSchedulingPolicy.from_dict(\n",
    "        {\"triggered\": \"true\"}\n",
    "    ),\n",
    ")\n",
    "\n",
    "churn_features_online_table = OnlineTable.from_dict(\n",
    "    {\n",
    "        \"name\": f\"{catalog}.{db}.advanced_churn_feature_table_online_table\",\n",
    "        \"spec\": churn_features_online_store_spec.as_dict(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f65476b2-9159-4cba-bef4-0bcb50050a0e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create the online table"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk.service.catalog import OnlineTable\n",
    "\n",
    "# Create the online table\n",
    "w.online_tables.create_and_wait(table = churn_features_online_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05128b90-83ba-4259-99af-91b34ad32886",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check the status of the online table"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "try:\n",
    "  online_table_exist = w.online_tables.get(f\"{catalog}.{db}.advanced_churn_feature_table_online_table\")\n",
    "  pprint(online_table_exist)\n",
    "except Exception as e:\n",
    "  pprint(e)\n",
    "\n",
    "pprint(online_table_exist.status.detailed_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e44846ce-4c61-475f-8dc7-74f71a3cf9cd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Wait for Online Table to be ready"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "ready_state = online_table_exist.status.detailed_state.ONLINE_NO_PENDING_UPDATE\n",
    "current_state = online_table_exist.status.detailed_state\n",
    "\n",
    "try:\n",
    "  while current_state != ready_state:\n",
    "    ol_table_create = w.online_tables.get(f\"{catalog}.{db}.advanced_churn_feature_table_online_table\")\n",
    "    current_state = ol_table_create.status.detailed_state\n",
    "except Exception as e:\n",
    "  pprint(e)\n",
    "\n",
    "pprint(current_state)\n",
    "print(\"Online table is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1acb7645-4259-4d18-a341-ce97de552d6c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Refresh online table (optional in case new data was added or offline table was dropped and re-created with new data))"
    }
   },
   "outputs": [],
   "source": [
    "# Trigger an online table refresh by calling the pipeline API\n",
    "# w.pipelines.start_update(pipeline_id=online_table_spec.pipeline_id, full_refresh=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7850ed24-c608-4251-8cdb-74956a869a95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Review Featurization Logic to compute features on-demand\n",
    "\n",
    "We have deployed the online table and features are now available on-demand at low latency to the model.\n",
    "\n",
    "Recall that we have also defined a function earlier to calculate the `avg_price_increase` feature on-demand. Let's review the function here.\n",
    "\n",
    "This function was specified as a feature function when creating the training dataset with the Feature Engineering Client in the model training notebook. This information is logged with the model in MLflow. That means that at serving time, not only does the model know to retrieve features from the online table, but it also know that the `avg_price_increase` feature has to be computed on-demand using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16b51661-cd1c-4349-a7e9-622067fedad6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE FUNCTION EXTENDED avg_price_increase;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "219bf868-4acb-48fb-aeea-974b8cd55d9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Deploying the model for real-time inference\n",
    "\n",
    "To make the model available for real-time inference through a REST API we will deploy to a Model Serving endpoint.\n",
    "\n",
    "Our marketing team can point customer-facing applications used by many concurrent customers to this endpoint. Databricks makes it easy for ML teams to deploy this type of low-latency and high-concurrency applications. Model Serving handles all the infrastructure, deployment and scaling for you. You just need to deploy the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b98f552e-0e02-419a-96fc-74b23cdb962f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Promote model for real-time serving\n",
    "\n",
    "We have seen earlier how to use the `@Champion` and `@Challenger` aliases to promote models to be called in a batch pipeline.\n",
    "\n",
    "Since real-time inference is another way the model will be consumed, we need a workflow to ensure the model is deployed safely. You can adopt different strategies to deploy a new model version as an endpoint. We will look at  A/B testing as an example here. Other strategies include canary deploying, shadow testing, etc.\n",
    "\n",
    "In A/B testing, there is a 'live' model served in production. When we have a new model version, we want to divert a percentage of our online traffic to this new model version. We let the new model version predict if these customers will churn, and compare the results to that of the 'live' model. We monitor the results. If the results are acceptable, then we divert all traffic to the new model version, and it now becomes the new 'live' version.\n",
    "\n",
    "Let's introduce a third alias, `@Production` to track this workflow:\n",
    "\n",
    "- `@Production`: Production model that is 'live'\n",
    "- `@Champion`: New model version that was promoted after Champion-Challenger testing\n",
    "- `@Challenger`: Model that challenges the Champion. Never gets deployed for real-time serving unless promoted to Champion.\n",
    "\n",
    "Model Serving lets you deploy multiple model versions to a serving endpoint and specify a traffic split between these versions. For example, when there is a new Champion model to be A/B tested, you can route 20% of the traffic to the the Champion model and let the Production model process only 80%.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/mlops/advanced/06_traffic_percent.png?raw=true\" width=\"450\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Since we are deplying a model as an endpoint for the first time, we will promote set the `@Production` alias to the Champion model and deploy it for serving against 100% traffic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35dfc298-473c-409c-a9cf-c8a2321a8631",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"advanced_mlops_churn_ep\"\n",
    "\n",
    "# Fully qualified model name\n",
    "model_name = f\"{catalog}.{db}.advanced_mlops_churn\"\n",
    "model_version = client.get_model_version_by_alias(name=model_name, alias=\"Champion\").version # Get champion version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f4811ad-e804-4bbb-a672-c0300aaee466",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Promote Champion model to Production\n",
    "client.set_registered_model_alias(name=model_name, alias=\"Production\", version=model_version)\n",
    "\n",
    "print(f\"Promoting {model_name} versions {model_version} from Champion to Production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ce927fa-8253-4daa-89b0-bdac1c14a387",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Create the Model Serving endpoint\n",
    "\n",
    "We'll now create the Model Serving endpoint. This is very simple once the model has been registered in Unity Catalog. You can do it through the UI, or by using the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba95d30a-46e3-4f8b-bb53-5d7296f72f14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### OPTION 1: Use the UI\n",
    "\n",
    "Go to the **Serving** section under **Machine Learning** and click **Create serving endpoint**.\n",
    "\n",
    "Open the Model page and click on \"Serving\". It'll start your model behind a REST endpoint and you can start sending your HTTP requests!\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/mlops/advanced/06_create_serving_endpoint.gif?raw=true\" width=\"854\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Fill in the following fields:\n",
    "\n",
    "* **Name**: `dbdemos_mlops_advanced_churn`\n",
    "  * This is the name of the serving endpoint\n",
    "* **Entity**: Type `mlops_churn` and choose the model registered from the previous notebooks.\n",
    "  * This is the Unity Catalog-registered model that you want to serve.\n",
    "* **Compute type**: Leave it as **CPU**\n",
    "  * This is the column in the source table to use as the timeseries key.\n",
    "* **Compute scale out**: Choose **Small**\n",
    "  * This determines how many concurrent requests the endpoint can handle.\n",
    "* **Scale to zero**: Keep it checked\n",
    "  * This allows the serving endpoint to scale down to zero when there are no requests\n",
    "\n",
    "Click **Create** and wait for the endpoint to provision. Be patient, as this can take more than an hour. Take a break and check back later.\n",
    "\n",
    "When the endpoint is ready, it should show that the status is **Ready**.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/mlops/advanced/06_served_model.png?raw=true\" width=\"854\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Refer to the documentation to learn more about creating and managing serving endpoints. ([AWS](https://docs.databricks.com/machine-learning/model-inference/serverless/create-manage-serverless-endpoints.html)|[Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-inference/serverless/create-manage-serverless-endpoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "507840cc-903c-4789-a79f-81e4bb02e020",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### OPTION 2: Enable model serving endpoint via API call\n",
    "\n",
    "What is done above using the UI to create a serving endpoint can also be done programmatically. The code below automatically creates a model serving endpoint for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "074fb31e-875d-4df4-a856-e68c179fac3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create/Update serving endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db202d8c-1a19-4ef5-ba16-b465f24cfc61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Parse model name from UC namespace\n",
    "served_model_name =  model_name.split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12e95090-2a5d-4b2c-b7e4-dd8af79d4120",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk.service.serving import EndpointCoreConfigInput\n",
    "\n",
    "endpoint_config_dict = {\n",
    "    \"served_models\": [\n",
    "        # Add models to be served to this list\n",
    "        {\n",
    "            \"model_name\": model_name,\n",
    "            \"model_version\": model_version,\n",
    "            \"scale_to_zero_enabled\": True,\n",
    "            \"workload_size\": \"Small\",\n",
    "        },\n",
    "    ],\n",
    "    \"traffic_config\": {\n",
    "        \"routes\": [\n",
    "            # Add versions of the model to be served to this list\n",
    "            # Make sure that traffic_percentage adds up to 100 over all served models\n",
    "            # Naming convention for served_model_name: <registered_model_name>-<model_version>\n",
    "            {\"served_model_name\": f\"{served_model_name}-{model_version}\", \"traffic_percentage\": 100},\n",
    "        ]\n",
    "    },\n",
    "    \"auto_capture_config\":{\n",
    "        \"catalog_name\": catalog,\n",
    "        \"schema_name\": db,\n",
    "        \"table_name_prefix\": \"advanced_churn_served\"\n",
    "    }\n",
    "}\n",
    "\n",
    "endpoint_config = EndpointCoreConfigInput.from_dict(endpoint_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "272ccac2-f04b-4358-b03b-5be971871f9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk.service.serving import EndpointTag\n",
    "\n",
    "try:\n",
    "  # Create and do not wait. Check readiness of endpoint in next cell.\n",
    "  w.serving_endpoints.create(\n",
    "    name=endpoint_name,\n",
    "    config=endpoint_config,\n",
    "    tags=[EndpointTag.from_dict({\"key\": \"dbdemos\", \"value\": \"advanced_mlops_churn\"})]\n",
    "  )\n",
    "  \n",
    "  print(f\"Creating endpoint {endpoint_name} with models {model_name} version {model_version}\")\n",
    "\n",
    "except Exception as e:\n",
    "  if f\"Endpoint with name '{endpoint_name}' already exists\" in e.args[0]:\n",
    "    print(f\"Endpoint with name {endpoint_name} already exists, updating it with model {model_name}-{model_version} ({str(e)})\")\n",
    "\n",
    "    w.serving_endpoints.update_config(\n",
    "      name=endpoint_name,\n",
    "      served_models=endpoint_config.served_models,\n",
    "      traffic_config=endpoint_config.traffic_config\n",
    "    )\n",
    "  else:\n",
    "    raise(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b51d9bf-11d0-4d5b-8525-8a99541ca00a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Wait/Verify that endpoint is ready\n",
    "\n",
    "Leave the following cell to run. It may take an hour or so for the endpoint to be ready. Take a break and check back later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e1e7baa-3941-48bc-867d-3bedd0b4b163",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# Wait for endpoint to be ready or finish updating\n",
    "endpoint = w.serving_endpoints.wait_get_serving_endpoint_not_updating(endpoint_name, timeout=timedelta(minutes=120))\n",
    "\n",
    "assert endpoint.state.config_update.value == \"NOT_UPDATING\" and endpoint.state.ready.value == \"READY\" , \"Endpoint not ready or failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f25cec87-73af-473e-8e0f-29d492690599",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Send payloads via REST call\n",
    "\n",
    "You can test the endpoint on the UI. Copy and paste this json input to the UI to test the endpoint.\n",
    "\n",
    "<br>\n",
    "\n",
    "```\n",
    "{\n",
    "  \"dataframe_records\": [\n",
    "    {\"customer_id\": \"0002-ORFBO\", \"scoring_timestamp\": \"2024-09-10\"},\n",
    "    {\"customer_id\": \"0003-MKNFE\", \"scoring_timestamp\": \"2024-9-10\"}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/mlops/advanced/06_online_scoring.gif?raw=true\" width=\"950\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Run the next cells to call the endpoint programatically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b2b6f4c-1881-4fd7-bda5-d04b173d5f69",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get input example directly from mlfow model or hard-code"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository\n",
    "from mlflow.models import Model\n",
    "\n",
    "# Setting these variables again in case the user skipped running the cells to deploy the model\n",
    "endpoint_name = \"advanced_mlops_churn_ep\"\n",
    "model_version = client.get_model_version_by_alias(name=model_name, alias=\"Champion\").version # Get champion version\n",
    "\n",
    "p = ModelsArtifactRepository(f\"models:/{model_name}/{model_version}\").download_artifacts(\"\") \n",
    "input_example =  Model.load(p).load_input_example(p)\n",
    "\n",
    "if input_example:\n",
    "  # Only works if model NOT logged with feature store client\n",
    "  dataframe_records =  [{input_example.to_dict(orient='records')}]\n",
    "else:\n",
    "  # Hard-code test-sample\n",
    "  dataframe_records = [\n",
    "    {\"customer_id\": \"0002-ORFBO\", \"transaction_ts\": \"2024-09-10\"},\n",
    "    {\"customer_id\": \"0003-MKNFE\", \"transaction_ts\": \"2024-09-10\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "743918a2-7939-4a72-b508-d84de27d6621",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Query endpoint"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Wait 60 sec for endpoint so that the endpoint is fully ready to available errors in the next command\n",
    "time.sleep(60)\n",
    "\n",
    "print(\"Churn inference:\")\n",
    "response = w.serving_endpoints.query(name=f\"{endpoint_name}\", dataframe_records=dataframe_records)\n",
    "print(response.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4291577b-2e3d-46f9-a553-a43523beb1a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Congratulations! You have deployed a feature and model serving endpoint.\n",
    "\n",
    "Now that we are able to both make predictions in batches, and predict a customer's propensity to churn in real-time, we will next look at how we can monitor the model's performance.\n",
    "\n",
    "With inference tables availables we can create a monitor to track our ML's system behavior over time (feature drifts, prediction drift, label drift, model accuracy and metrics etc.)\n",
    "\n",
    "Next steps:\n",
    "* [Create monitor for model performance]($./07_model_monitoring)\n",
    "* [Detect drift and trigger model retrain]($./08_drift_detection)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "06_serve_features_and_model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
